{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E9vQYbDf8I92"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, RepeatVector\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from numpy.core.fromnumeric import size\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate import meteor_score\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVrRgh2dA6T7",
        "outputId": "d90af861-f136-4fc1-cc4e-002e024c4599"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/modelFinal/trained_model.h5\"\n",
        "model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "kpuUxHnsA6hw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(text):\n",
        "    text = text.replace('\\n', ' ')  # remove newline\n",
        "    text = text.replace('/', ' ')  # remove forward slashes\n",
        "    text = re.sub(r'\\s+', ' ', text)  # replace multiple whitespace with a single space\n",
        "    text = re.sub(r'[^a-zA-Z0-9äöüÄÖÜß ]', '', text)  # remove non-alphanumeric characters\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "09t3k89ABk8I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/df_train.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/df_test.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/df_val.csv\")\n",
        "\n",
        "train = df_train.values.tolist()\n",
        "test = df_test.values.tolist()\n",
        "val = df_val.values.tolist()\n"
      ],
      "metadata": {
        "id": "KTfAVbNTDTkF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "vS9bV1jHDTnQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sentences = []\n",
        "for sentence in train:\n",
        "    en_sentences.append(sentence[0])\n",
        "en_tokenizer = tokenization(en_sentences)\n",
        "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "en_length = 15 #Histogram\n",
        "print('English Vocab: %d' % en_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3ld0OGqDTpt",
        "outputId": "f4ceadcd-3d69-470d-ac53-9f8f9a36596b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocab: 14341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "de_sentences = []\n",
        "for sentence in train:\n",
        "    de_sentences.append(sentence[1])\n",
        "de_tokenizer = tokenization(de_sentences)\n",
        "de_vocab_size = len(de_tokenizer.word_index) + 1\n",
        "de_length = 15 #Hisogram\n",
        "print('German Vocab: %d' % de_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEKSsiL_DTsV",
        "outputId": "f81484fb-35cc-413a-83f6-14cd1705d998"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German Vocab: 28493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sequences(tokenizer, length, lines):\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ],
      "metadata": {
        "id": "pK8pl-U-Eb9I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = encode_sequences(en_tokenizer, en_length, [sentence[0] for sentence in train])\n",
        "trainY = encode_sequences(de_tokenizer, de_length, [sentence[1] for sentence in train])\n",
        "\n",
        "testX = encode_sequences(en_tokenizer, en_length, [sentence[0] for sentence in test])\n",
        "testY = encode_sequences(de_tokenizer, de_length, [sentence[1] for sentence in test])\n",
        "\n",
        "valX = encode_sequences(en_tokenizer, en_length, [sentence[0] for sentence in val])\n",
        "valY = encode_sequences(de_tokenizer, de_length, [sentence[1] for sentence in val])"
      ],
      "metadata": {
        "id": "rMxYVG6ZEb_o"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None"
      ],
      "metadata": {
        "id": "4JnU-fsaFQri"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing if model load works\n",
        "#Create subset of data to avoid memory issues\n",
        "testX = testX[0:1000]\n",
        "testY = testY[0:1000]\n",
        "\n",
        "preds = np.argmax(model.predict(testX.reshape((testX.shape[0],testX.shape[1]))), axis=-1)\n",
        "\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], de_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], de_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "\n",
        "    preds_text.append(' '.join(temp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MctUttjnEcB9",
        "outputId": "7a71891b-b1cb-4b0c-e462-fc7e7224f8e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 27s 852ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_sentences = [sentence[0] for sentence in test[0:1000]]\n",
        "actual_german = [sentence[1] for sentence in test[0:1000]]\n",
        "\n",
        "pred_df = pd.DataFrame({'english': initial_sentences[0:21], 'predicted german': preds_text[0:21], 'actual german': actual_german[0:21]})\n",
        "pred_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "12APXMYZEcEd",
        "outputId": "f03d0638-9e5c-4890-f75b-8e268cc165bf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              english  \\\n",
              "0                                    where is the bus   \n",
              "1   tom thinks it impossible for mary to break the...   \n",
              "2   wed better go to another room so they cant hea...   \n",
              "3                                  hide in the closet   \n",
              "4   tom asked mary to tell him about the house she...   \n",
              "5                           tom is my flesh and blood   \n",
              "6                                you are what you eat   \n",
              "7                         shes a single mother of two   \n",
              "8                    i am losing my patience with you   \n",
              "9                          this meeting room is small   \n",
              "10                                why are people here   \n",
              "11                                           its here   \n",
              "12                            do you accept visa card   \n",
              "13         as we grow older our memory becomes weaker   \n",
              "14                          check to see if its right   \n",
              "15     has tom already told you what needs to be done   \n",
              "16                          i almost never drink milk   \n",
              "17  i canceled my appointment because of urgent bu...   \n",
              "18         i love tom and at the same time i hate him   \n",
              "19                                      i made tom go   \n",
              "20                 do you have any complaint about it   \n",
              "\n",
              "                                     predicted german  \\\n",
              "0                           wo ist der bus              \n",
              "1                 tom glaubt es maria  das  zu          \n",
              "2   wir sollten wir noch ein nicht  was können wir...   \n",
              "3                            froh sie den               \n",
              "4                     sie  ihm einem   sie     ein      \n",
              "5                         tom ist mein und              \n",
              "6                       du bist was du isst             \n",
              "7                   sie ist eine ihrer frau             \n",
              "8         ich verliere die geduld mit geduld            \n",
              "9                dieses diesem ist in klein             \n",
              "10                    warum sind die leute              \n",
              "11                            es ist hier               \n",
              "12                       hast du ein karte              \n",
              "13                 wie wir   unser freut wird           \n",
              "14                      schau mal ob es das             \n",
              "15  hat tom dir schon gesagt was getan werden muss...   \n",
              "16                   ich trinke fast milch              \n",
              "17     ich habe meinen versehen als ich statt           \n",
              "18                 ich liebe tom und ich  ihn           \n",
              "19                      ich habe tom gehen              \n",
              "20            hast du irgendwelche darüber              \n",
              "\n",
              "                                        actual german  \n",
              "0                                      wo ist der bus  \n",
              "1   tom glaubt dass es maria unmöglich sei den rek...  \n",
              "2   wir gehen besser in ein anderes zimmer damit n...  \n",
              "3                            versteck dich im schrank  \n",
              "4   tom bat mary ihm von dem haus zu erzählen in d...  \n",
              "5                       tom ist mein fleisch und blut  \n",
              "6                               ihr seid was ihr esst  \n",
              "7   sie ist eine alleinerziehende mutter zweier ki...  \n",
              "8                   ich verliere die geduld mit ihnen  \n",
              "9                        das sitzungszimmer ist klein  \n",
              "10                          warum sind die leute hier  \n",
              "11                                        es ist hier  \n",
              "12                         akzeptieren sie visakarten  \n",
              "13  mit zunehmendem alter wird unser gedächtnis sc...  \n",
              "14                           schau nach ob das stimmt  \n",
              "15   hat dir tom schon gesagt was gemacht werden muss  \n",
              "16                          ich trinke fast nie milch  \n",
              "17  ich habe den termin wegen dringender geschäftl...  \n",
              "18       ich liebe tom und gleichzeitig hasse ich ihn  \n",
              "19                   ich habe tom veranlasst zu gehen  \n",
              "20     haben sie einen anlass zur beschwerde deswegen  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59430994-535a-4e43-8c02-a8a7fc2ea9b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>predicted german</th>\n",
              "      <th>actual german</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>where is the bus</td>\n",
              "      <td>wo ist der bus</td>\n",
              "      <td>wo ist der bus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tom thinks it impossible for mary to break the...</td>\n",
              "      <td>tom glaubt es maria  das  zu</td>\n",
              "      <td>tom glaubt dass es maria unmöglich sei den rek...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wed better go to another room so they cant hea...</td>\n",
              "      <td>wir sollten wir noch ein nicht  was können wir...</td>\n",
              "      <td>wir gehen besser in ein anderes zimmer damit n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hide in the closet</td>\n",
              "      <td>froh sie den</td>\n",
              "      <td>versteck dich im schrank</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tom asked mary to tell him about the house she...</td>\n",
              "      <td>sie  ihm einem   sie     ein</td>\n",
              "      <td>tom bat mary ihm von dem haus zu erzählen in d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tom is my flesh and blood</td>\n",
              "      <td>tom ist mein und</td>\n",
              "      <td>tom ist mein fleisch und blut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>you are what you eat</td>\n",
              "      <td>du bist was du isst</td>\n",
              "      <td>ihr seid was ihr esst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>shes a single mother of two</td>\n",
              "      <td>sie ist eine ihrer frau</td>\n",
              "      <td>sie ist eine alleinerziehende mutter zweier ki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i am losing my patience with you</td>\n",
              "      <td>ich verliere die geduld mit geduld</td>\n",
              "      <td>ich verliere die geduld mit ihnen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>this meeting room is small</td>\n",
              "      <td>dieses diesem ist in klein</td>\n",
              "      <td>das sitzungszimmer ist klein</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>why are people here</td>\n",
              "      <td>warum sind die leute</td>\n",
              "      <td>warum sind die leute hier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>its here</td>\n",
              "      <td>es ist hier</td>\n",
              "      <td>es ist hier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>do you accept visa card</td>\n",
              "      <td>hast du ein karte</td>\n",
              "      <td>akzeptieren sie visakarten</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>as we grow older our memory becomes weaker</td>\n",
              "      <td>wie wir   unser freut wird</td>\n",
              "      <td>mit zunehmendem alter wird unser gedächtnis sc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>check to see if its right</td>\n",
              "      <td>schau mal ob es das</td>\n",
              "      <td>schau nach ob das stimmt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>has tom already told you what needs to be done</td>\n",
              "      <td>hat tom dir schon gesagt was getan werden muss...</td>\n",
              "      <td>hat dir tom schon gesagt was gemacht werden muss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>i almost never drink milk</td>\n",
              "      <td>ich trinke fast milch</td>\n",
              "      <td>ich trinke fast nie milch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>i canceled my appointment because of urgent bu...</td>\n",
              "      <td>ich habe meinen versehen als ich statt</td>\n",
              "      <td>ich habe den termin wegen dringender geschäftl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>i love tom and at the same time i hate him</td>\n",
              "      <td>ich liebe tom und ich  ihn</td>\n",
              "      <td>ich liebe tom und gleichzeitig hasse ich ihn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>i made tom go</td>\n",
              "      <td>ich habe tom gehen</td>\n",
              "      <td>ich habe tom veranlasst zu gehen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>do you have any complaint about it</td>\n",
              "      <td>hast du irgendwelche darüber</td>\n",
              "      <td>haben sie einen anlass zur beschwerde deswegen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59430994-535a-4e43-8c02-a8a7fc2ea9b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59430994-535a-4e43-8c02-a8a7fc2ea9b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59430994-535a-4e43-8c02-a8a7fc2ea9b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Split sentences into tokens\n",
        "actual_german_tokens = [[sent.split()] for sent in actual_german]\n",
        "preds_text_tokens = [sent.split() for sent in preds_text]\n",
        "\n",
        "# Calculate BLEU scores\n",
        "bleu_score = corpus_bleu(actual_german_tokens, preds_text_tokens)\n",
        "\n",
        "print(\"The BLEU score is: \", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zufoZWbXMn1-",
        "outputId": "a0da5257-d189-48d2-d48e-68723bcc3b66"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BLEU score is:  0.21025976732050963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "\n",
        "for reference, candidate in zip(actual_german_tokens, preds_text_tokens):\n",
        "    scores.append(meteor_score.single_meteor_score(reference[0], candidate))\n",
        "\n",
        "average_meteor_score = sum(scores) / len(scores)\n",
        "\n",
        "print(average_meteor_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPvMb3IxY_kV",
        "outputId": "43668599-c130-4868-a4cb-505664c06115"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.46703515590863304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_german_text(english_text):\n",
        "    # Preprocess the English text and obtain token sequence\n",
        "    english_text = clean_data(english_text)\n",
        "    input_sequence = encode_sequences(en_tokenizer, en_length, [english_text])\n",
        "\n",
        "    #Multiclassification prediction\n",
        "    preds = np.argmax(model.predict(input_sequence.reshape((input_sequence.shape[0], input_sequence.shape[1]))), axis=-1)\n",
        "\n",
        "    preds_text = []\n",
        "    for i in preds:\n",
        "        temp = []\n",
        "        for j in range(len(i)):\n",
        "            t = get_word(i[j], de_tokenizer)\n",
        "            if j > 0:\n",
        "                if (t == get_word(i[j-1], de_tokenizer)) or (t == None):\n",
        "                    temp.append('')\n",
        "                else:\n",
        "                    temp.append(t)\n",
        "            else:\n",
        "                if(t == None):\n",
        "                    temp.append('')\n",
        "                else:\n",
        "                    temp.append(t)\n",
        "\n",
        "        preds_text.append(' '.join(temp))\n",
        "\n",
        "    return preds_text[0]\n",
        "\n",
        "\n",
        "english_input = input(\"Enter English Text Here: \", )\n",
        "predicted_german = predict_german_text(english_input)\n",
        "print(\"Predicted German Translation: \", predicted_german)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwHYW7qqB0md",
        "outputId": "2aa2b98f-216a-467d-cf02-14a697ef1026"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter English Text Here: testing\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "Predicted German Translation:                \n"
          ]
        }
      ]
    }
  ]
}