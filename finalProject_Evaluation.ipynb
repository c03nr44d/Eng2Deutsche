{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E9vQYbDf8I92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2001503b-9294-4a4e-d300-7a608084e174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, RepeatVector\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from numpy.core.fromnumeric import size\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate import meteor_score\n",
        "nltk.download('wordnet')\n",
        "from numpy.core.fromnumeric import size\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount google drive to get access to the data files and the model"
      ],
      "metadata": {
        "id": "urypw77QIAXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVrRgh2dA6T7",
        "outputId": "2f40550a-aa3a-46d4-d822-e78240bf8555"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in the pre-trained model"
      ],
      "metadata": {
        "id": "BdfH5mvpIL0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/modelFinal/trained_model.h5\"\n",
        "model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "kpuUxHnsA6hw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean the data"
      ],
      "metadata": {
        "id": "jRNM-AxTIRRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(text):\n",
        "    text = text.replace('\\n', ' ')  # remove newline\n",
        "    text = text.replace('/', ' ')  # remove forward slashes\n",
        "    text = re.sub(r'\\s+', ' ', text)  # replace multiple whitespace with a single space\n",
        "    text = re.sub(r'[^a-zA-Z0-9äöüÄÖÜß ]', '', text)  # remove non-alphanumeric characters\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "09t3k89ABk8I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading in the datasets and converting them to lists. We take a sample of the test set, because when running the whole test set, our notebook crashes because it uses too much RAM.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BYXChf5yIXzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/df_train.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/df_test.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/df_val.csv\")\n",
        "\n",
        "df_test = df_test.sample(1000)\n",
        "\n",
        "train = df_train.values.tolist()\n",
        "test = df_test.values.tolist()\n",
        "val = df_val.values.tolist()\n"
      ],
      "metadata": {
        "id": "KTfAVbNTDTkF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to build a tokenizer"
      ],
      "metadata": {
        "id": "2nlsPYCaIiIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "vS9bV1jHDTnQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the English sentences"
      ],
      "metadata": {
        "id": "NfZahovbIlVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_sentences = []\n",
        "for sentence in train:\n",
        "    en_sentences.append(sentence[0])\n",
        "en_tokenizer = tokenization(en_sentences)\n",
        "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
        "en_length = 15 #Taken from the Histogram\n",
        "print('English Vocab: %d' % en_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3ld0OGqDTpt",
        "outputId": "c5023569-9d56-4360-eeac-3b770597375e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocab: 14341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the German sentences"
      ],
      "metadata": {
        "id": "YR-eT77ZI2ZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "de_sentences = []\n",
        "for sentence in train:\n",
        "    de_sentences.append(sentence[1])\n",
        "de_tokenizer = tokenization(de_sentences)\n",
        "de_vocab_size = len(de_tokenizer.word_index) + 1\n",
        "de_length = 15 #Hisogram\n",
        "print('German Vocab: %d' % de_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEKSsiL_DTsV",
        "outputId": "3c93b008-0166-4094-ee97-dbd437697994"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German Vocab: 28493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function that zero pads the sentences based on tokenizer for training"
      ],
      "metadata": {
        "id": "b14rvw9XJKm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sequences(tokenizer, length, lines):\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ],
      "metadata": {
        "id": "pK8pl-U-Eb9I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The source sequences, or our English sentences will be encoded as X. While our target German sequences will be encoded as Y"
      ],
      "metadata": {
        "id": "gWm837fyJQ3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = encode_sequences(en_tokenizer, en_length, [sentence[0] for sentence in train])\n",
        "trainY = encode_sequences(de_tokenizer, de_length, [sentence[1] for sentence in train])\n",
        "\n",
        "testX = encode_sequences(en_tokenizer, en_length, [sentence[0] for sentence in test])\n",
        "testY = encode_sequences(de_tokenizer, de_length, [sentence[1] for sentence in test])\n",
        "\n",
        "valX = encode_sequences(en_tokenizer, en_length, [sentence[0] for sentence in val])\n",
        "valY = encode_sequences(de_tokenizer, de_length, [sentence[1] for sentence in val])"
      ],
      "metadata": {
        "id": "rMxYVG6ZEb_o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions that returns word assigned to index in tokenizer"
      ],
      "metadata": {
        "id": "YSjha1nfJZG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None"
      ],
      "metadata": {
        "id": "4JnU-fsaFQri"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the model to get the predicted translations"
      ],
      "metadata": {
        "id": "L1m4CMA9J1y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(model.predict(testX.reshape((testX.shape[0],testX.shape[1]))), axis=-1)\n",
        "\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], de_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], de_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "\n",
        "    preds_text.append(' '.join(temp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MctUttjnEcB9",
        "outputId": "ad833624-68a0-46ec-d2d7-d704ea51bcc2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 19s 518ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the English sentences, our predicted German translation, and the actual German translation"
      ],
      "metadata": {
        "id": "6kBMeZANKEco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_sentences = [sentence[0] for sentence in test]\n",
        "actual_german = [sentence[1] for sentence in test]\n",
        "\n",
        "pred_df = pd.DataFrame({'english': initial_sentences[0:20], 'predicted german': preds_text[0:20], 'actual german': actual_german[0:20]})\n",
        "pred_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "12APXMYZEcEd",
        "outputId": "8ff14fa3-0250-4730-c818-c09b6572ece9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              english  \\\n",
              "0   preventive measures are much more effective th...   \n",
              "1                           they are crazy about jazz   \n",
              "2                     they sat on a bench in the park   \n",
              "3                               it wasnt that serious   \n",
              "4                  there are a lot of eggs in the box   \n",
              "5                          i met a dog on my way home   \n",
              "6                       who is their homeroom teacher   \n",
              "7                     there may be some truth to this   \n",
              "8                           she is a wellknown singer   \n",
              "9                       theyre crazy about each other   \n",
              "10                        he was ashamed of his tears   \n",
              "11                              eat whatever you like   \n",
              "12                           lets make the best of it   \n",
              "13                      he came to ask us to help him   \n",
              "14                                she held her breath   \n",
              "15                              its a simple question   \n",
              "16                                     i got you this   \n",
              "17                       this key wont go in the lock   \n",
              "18                                  when will we meet   \n",
              "19                                tom got off the bus   \n",
              "\n",
              "                                 predicted german  \\\n",
              "0                        die sind die               \n",
              "1       sie sind verrückt nach verrückt             \n",
              "2              sie saßen auf einer bank             \n",
              "3               das war das nicht ernst             \n",
              "4           es der eier  in der schachtel           \n",
              "5                 ich habe meinen hund              \n",
              "6                        wer ist ihre               \n",
              "7                     es kann etwas   zu            \n",
              "8                sie ist eine sängerin              \n",
              "9        sie sind verrückt über anderen             \n",
              "10             er hat sich seine seiner             \n",
              "11                    iss was du immer              \n",
              "12           lasst wir das besten  lösen            \n",
              "13            er kam uns um uns zu bitten           \n",
              "14                  sie hielt sie fest              \n",
              "15          das ist eine einfache frage             \n",
              "16                    ich habe dir das              \n",
              "17  dieses wagen wird nicht die toilette            \n",
              "18          wann werden wir uns treffen             \n",
              "19                tom stieg aus dem bus             \n",
              "\n",
              "                                        actual german  \n",
              "0   gegenmaßnahmen sind um einiges effektiver als ...  \n",
              "1                         sie sind verrückt nach jazz  \n",
              "2                    sie saßen auf einer bank im park  \n",
              "3                      so ernst war das nicht gemeint  \n",
              "4                    in der schachtel sind viele eier  \n",
              "5    ich habe auf meinem heimweg einen hund getroffen  \n",
              "6                           wer ist ihr klassenlehrer  \n",
              "7                   es könnte etwas wahres daran sein  \n",
              "8                 sie ist eine sehr bekannte sängerin  \n",
              "9                      sie sind verrückt nacheinander  \n",
              "10                      er schämte sich seiner tränen  \n",
              "11                                   iss was du magst  \n",
              "12                  lasst uns das beste daraus machen  \n",
              "13                      er kam uns um hilfe zu bitten  \n",
              "14                              sie hielt den atem an  \n",
              "15                        das ist eine einfache frage  \n",
              "16                       das habe ich dir mitgebracht  \n",
              "17        dieser schlüssel passt nicht in das schloss  \n",
              "18                        wann werden wir uns treffen  \n",
              "19                              tom stieg aus dem bus  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da759606-7916-412a-ba0c-b4668ef3e60d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>predicted german</th>\n",
              "      <th>actual german</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>preventive measures are much more effective th...</td>\n",
              "      <td>die sind die</td>\n",
              "      <td>gegenmaßnahmen sind um einiges effektiver als ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they are crazy about jazz</td>\n",
              "      <td>sie sind verrückt nach verrückt</td>\n",
              "      <td>sie sind verrückt nach jazz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they sat on a bench in the park</td>\n",
              "      <td>sie saßen auf einer bank</td>\n",
              "      <td>sie saßen auf einer bank im park</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>it wasnt that serious</td>\n",
              "      <td>das war das nicht ernst</td>\n",
              "      <td>so ernst war das nicht gemeint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>there are a lot of eggs in the box</td>\n",
              "      <td>es der eier  in der schachtel</td>\n",
              "      <td>in der schachtel sind viele eier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i met a dog on my way home</td>\n",
              "      <td>ich habe meinen hund</td>\n",
              "      <td>ich habe auf meinem heimweg einen hund getroffen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>who is their homeroom teacher</td>\n",
              "      <td>wer ist ihre</td>\n",
              "      <td>wer ist ihr klassenlehrer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>there may be some truth to this</td>\n",
              "      <td>es kann etwas   zu</td>\n",
              "      <td>es könnte etwas wahres daran sein</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>she is a wellknown singer</td>\n",
              "      <td>sie ist eine sängerin</td>\n",
              "      <td>sie ist eine sehr bekannte sängerin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>theyre crazy about each other</td>\n",
              "      <td>sie sind verrückt über anderen</td>\n",
              "      <td>sie sind verrückt nacheinander</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>he was ashamed of his tears</td>\n",
              "      <td>er hat sich seine seiner</td>\n",
              "      <td>er schämte sich seiner tränen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>eat whatever you like</td>\n",
              "      <td>iss was du immer</td>\n",
              "      <td>iss was du magst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>lets make the best of it</td>\n",
              "      <td>lasst wir das besten  lösen</td>\n",
              "      <td>lasst uns das beste daraus machen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>he came to ask us to help him</td>\n",
              "      <td>er kam uns um uns zu bitten</td>\n",
              "      <td>er kam uns um hilfe zu bitten</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>she held her breath</td>\n",
              "      <td>sie hielt sie fest</td>\n",
              "      <td>sie hielt den atem an</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>its a simple question</td>\n",
              "      <td>das ist eine einfache frage</td>\n",
              "      <td>das ist eine einfache frage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>i got you this</td>\n",
              "      <td>ich habe dir das</td>\n",
              "      <td>das habe ich dir mitgebracht</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>this key wont go in the lock</td>\n",
              "      <td>dieses wagen wird nicht die toilette</td>\n",
              "      <td>dieser schlüssel passt nicht in das schloss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>when will we meet</td>\n",
              "      <td>wann werden wir uns treffen</td>\n",
              "      <td>wann werden wir uns treffen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>tom got off the bus</td>\n",
              "      <td>tom stieg aus dem bus</td>\n",
              "      <td>tom stieg aus dem bus</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da759606-7916-412a-ba0c-b4668ef3e60d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da759606-7916-412a-ba0c-b4668ef3e60d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da759606-7916-412a-ba0c-b4668ef3e60d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the sentences into tokens and calculate the BLEU score"
      ],
      "metadata": {
        "id": "EX2w-GqdKmbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual_german_tokens = [[sent.split()] for sent in actual_german]\n",
        "preds_text_tokens = [sent.split() for sent in preds_text]\n",
        "\n",
        "bleu_score = corpus_bleu(actual_german_tokens, preds_text_tokens)\n",
        "\n",
        "print(\"The BLEU score is: \", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zufoZWbXMn1-",
        "outputId": "2989ca86-9df5-480a-861e-3cbc075df0db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BLEU score is:  0.212969642634469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the METEOR score"
      ],
      "metadata": {
        "id": "0OXfD-2BKuNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "\n",
        "for reference, candidate in zip(actual_german_tokens, preds_text_tokens):\n",
        "    scores.append(meteor_score.single_meteor_score(reference[0], candidate))\n",
        "\n",
        "average_meteor_score = sum(scores) / len(scores)\n",
        "\n",
        "print(average_meteor_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPvMb3IxY_kV",
        "outputId": "3404a7ac-3f22-40a0-9ce0-4e4902808a11"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.456145166784418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function that lets you use the model for live translation"
      ],
      "metadata": {
        "id": "AqkuZ_XxKxqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_german_text(english_text):\n",
        "    # Preprocess the English text and obtain token sequence\n",
        "    english_text = clean_data(english_text)\n",
        "    input_sequence = encode_sequences(en_tokenizer, en_length, [english_text])\n",
        "\n",
        "    #Multiclassification prediction\n",
        "    preds = np.argmax(model.predict(input_sequence.reshape((input_sequence.shape[0], input_sequence.shape[1]))), axis=-1)\n",
        "\n",
        "    preds_text = []\n",
        "    for i in preds:\n",
        "        temp = []\n",
        "        for j in range(len(i)):\n",
        "            t = get_word(i[j], de_tokenizer)\n",
        "            if j > 0:\n",
        "                if (t == get_word(i[j-1], de_tokenizer)) or (t == None):\n",
        "                    temp.append('')\n",
        "                else:\n",
        "                    temp.append(t)\n",
        "            else:\n",
        "                if(t == None):\n",
        "                    temp.append('')\n",
        "                else:\n",
        "                    temp.append(t)\n",
        "\n",
        "        preds_text.append(' '.join(temp))\n",
        "\n",
        "    return preds_text[0]\n",
        "\n",
        "\n",
        "english_input = input(\"Enter English Text Here: \", )\n",
        "predicted_german = predict_german_text(english_input)\n",
        "print(\"Predicted German Translation: \", predicted_german)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwHYW7qqB0md",
        "outputId": "a8f9210f-3c07-4639-fb17-7a7566fb8208"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter English Text Here: I like people\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "Predicted German Translation:  ich mag die leute           \n"
          ]
        }
      ]
    }
  ]
}