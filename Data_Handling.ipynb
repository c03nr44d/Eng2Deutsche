{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkdOFb0gDs-r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, RepeatVector\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import random\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in the data"
      ],
      "metadata": {
        "id": "ju-ZAvtjGeMs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrqeDi2lDs-v"
      },
      "outputs": [],
      "source": [
        "def load_data(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        return f.read().splitlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean the data"
      ],
      "metadata": {
        "id": "q_UtLwstDxQi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFZIpDXEwW-p"
      },
      "outputs": [],
      "source": [
        "def clean_data(text):\n",
        "    text = text.replace('\\n', ' ')  # remove newline\n",
        "    text = text.replace('/', ' ')  # remove forward slashes\n",
        "    text = re.sub(r'\\s+', ' ', text)  # replace multiple whitespace with a single space\n",
        "    text = re.sub(r'[^a-zA-Z0-9äöüÄÖÜß ]', '', text)  # remove non-alphanumeric characters\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into 60% training, 20% validation, and 20% testing data."
      ],
      "metadata": {
        "id": "CMxmvY9aEhX9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIjO1Le5Ds-w"
      },
      "outputs": [],
      "source": [
        "def split_data(df):\n",
        "\n",
        "    train_data, remaining_data = train_test_split(df, test_size=0.4, random_state=42)\n",
        "    test_data, val_data = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
        "\n",
        "    return train_data, test_data, val_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in the data"
      ],
      "metadata": {
        "id": "T1GrtQw0E6xO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJzSmR7KDs-x",
        "outputId": "ef964feb-15a2-4291-bbbe-9c6cf119ee0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Go.', 'Hi.', 'Hi.', 'Run!', 'Run.', 'Wow!', 'Wow!', 'Fire!', 'Help!', 'Help!']\n",
            "['Geh.', 'Hallo!', 'Grüß Gott!', 'Lauf!', 'Lauf!', 'Potzdonner!', 'Donnerwetter!', 'Feuer!', 'Hilfe!', 'Zu Hülf!']\n"
          ]
        }
      ],
      "source": [
        "loaded_data = load_data(r\"C:\\Users\\imaxo\\Desktop\\RUG FSE\\Natural Language Processing\\Project\\deu.txt\")\n",
        "\n",
        "en_data = []\n",
        "de_data = []\n",
        "\n",
        "for row in loaded_data:\n",
        "    english, deutsche, garbage = row.split('\\t')\n",
        "    en_data.append(english)\n",
        "    de_data.append(deutsche)\n",
        "\n",
        "print(en_data[0:10])\n",
        "print(de_data[0:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the cleaning function to clean the data"
      ],
      "metadata": {
        "id": "MeUF1xDTFAxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9oh0pWnDs-y",
        "outputId": "3aeee609-57c9-43f5-e9f3-489a4c752953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['go', 'hi', 'hi', 'run', 'run', 'wow', 'wow', 'fire', 'help', 'help']\n",
            "['geh', 'hallo', 'grüß gott', 'lauf', 'lauf', 'potzdonner', 'donnerwetter', 'feuer', 'hilfe', 'zu hülf']\n",
            "227080\n",
            "227080\n"
          ]
        }
      ],
      "source": [
        "en_cleaned = [clean_data(text) for text in en_data]\n",
        "de_cleaned = [clean_data(text) for text in de_data]\n",
        "\n",
        "print(en_cleaned[0:10])\n",
        "print(de_cleaned[0:10])\n",
        "print(len(en_cleaned))\n",
        "print(len(de_cleaned))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert seperate English and German sets into one list."
      ],
      "metadata": {
        "id": "kWpIqxf3FPUE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2fHKrI8Ds-y",
        "outputId": "5068bfd0-0884-4179-b8a2-01045b6641f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "227080\n"
          ]
        }
      ],
      "source": [
        "data = list(zip(en_cleaned, de_cleaned))\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initially we wanted to use a subset, but once we switched datasets we are actually using the entire dataset, therefore we actually take 100% of the data as a 'sample'. Additionaly we call the split function to split up the data."
      ],
      "metadata": {
        "id": "5VK8ruyYFfu2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJr59UxNDs-z",
        "outputId": "908aeca1-d152-4aac-9886-6b2c04249a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('you have to get enough sleep', 'du musst genug schlaf bekommen')\n",
            "227080\n"
          ]
        }
      ],
      "source": [
        "def get_data_subset(data, fraction):\n",
        "    data_subset = random.sample(data, int(len(data) * fraction))\n",
        "    return data_subset\n",
        "\n",
        "data_reduced = get_data_subset(data, 1)  #x% of the data as a subset\n",
        "print(data_reduced[12])\n",
        "print(len(data_reduced))\n",
        "data_train, data_test, data_val = split_data(data_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noN8jaXQDs-0",
        "outputId": "45537c5e-6824-42e4-c9c1-481092f6d878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "136248 45416 45416\n"
          ]
        }
      ],
      "source": [
        "print(len(data_train), len(data_test), len(data_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert lists to dataframes"
      ],
      "metadata": {
        "id": "tPMaFKRjF8jm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlL0b31fDs-1"
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(data_train)\n",
        "df_test = pd.DataFrame(data_test)\n",
        "df_val = pd.DataFrame(data_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the dataframes to csv files"
      ],
      "metadata": {
        "id": "s74Y4DDkGEVp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZNxg6r7Ds-3"
      },
      "outputs": [],
      "source": [
        "df_train.to_csv('df_train.csv', index=False)\n",
        "df_test.to_csv('df_test.csv', index=False)\n",
        "df_val.to_csv('df_val.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQoPPapdDs-4"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"C:/Users/imaxo/Desktop/RUG FSE/Natural Language Processing/Project/df_train.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test whether the data loaded in well"
      ],
      "metadata": {
        "id": "kOW_g6OqGOh7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNRrkfX3Ds-4",
        "outputId": "5c5355f1-60c4-49ec-b651-009a9e375b5c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>why didnt i listen to you</td>\n",
              "      <td>warum habe ich dir nicht zugehört</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ancient coins were found inside the mysterious...</td>\n",
              "      <td>in dem rätselhaften grab wurden antike münzen ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>he has a nice income</td>\n",
              "      <td>er hat ein gutes einkommen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tom is wearing a widebrimmed hat</td>\n",
              "      <td>tom trägt einen breitkrempigen hut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>why not take a few days off</td>\n",
              "      <td>warum nehmen sie sich nicht ein paar tage frei</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  \\\n",
              "0                          why didnt i listen to you   \n",
              "1  ancient coins were found inside the mysterious...   \n",
              "2                               he has a nice income   \n",
              "3                   tom is wearing a widebrimmed hat   \n",
              "4                        why not take a few days off   \n",
              "\n",
              "                                                   1  \n",
              "0                  warum habe ich dir nicht zugehört  \n",
              "1  in dem rätselhaften grab wurden antike münzen ...  \n",
              "2                         er hat ein gutes einkommen  \n",
              "3                 tom trägt einen breitkrempigen hut  \n",
              "4     warum nehmen sie sich nicht ein paar tage frei  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
